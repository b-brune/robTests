
@article{Yue74trim,
  title = {The Two-Sample Trimmed t for Unequal Population Variances},
  volume = {61},
  abstract = {The effect of nonnormality on the Welch approximate degrees of freedom t test is demonstrated.
A two-sample trimmed t statistic for unequal population variances is proposed and
its performance is also evaluated in comparison to the Welch t test under normality and
under long-tailed distributions. If the underlying distribution is long-tailed or contaminated
with outliers, the trimmed t is strongly recommended.},
  number = {1},
  journal = {Biometrika},
  author = {Yuen, Karen K.},
  year = {1974},
  pages = {165 - 170}
}

@article{WeiHot02robu,
  title = {Robust Tests for the Two-Sample Location Problem},
  volume = {31},
  abstract = {The t-test is uniformly most powerful for comparing the location parameters of two normal distributed populations. For non-normal data, robust tests can be more powerful than the t-test. We introduce a new parametric test statistic combining the p-values of the t-test and robust tests. In the normal distribution situation, this new test has a very small power loss compared to the t-test, but in the non-normal situation higher power than the t-test. The Pitman efficiency of 3$\pi$-1 = 0.955 gives an upper bound on the efficiency of nonparametric tests in the normal situation. Our new test (which is parametric) exceeds the Pitman bound when the sample sizes are small.},
  number = {2},
  journal = {Communications in Statistics - Simulation and Computation},
  author = {Weichert, Michael and Hothorn, Ludwig A.},
  year = {2002},
  pages = {175 - 187}
}

@article{ReeSta04robu,
  title = {Robust Two-Sample Statistics for Testing Equality of Means: {{A}} Simulation Study},
  volume = {31},
  doi = {10.1080/0266476042000214529},
  abstract = {When testing the equality of the means from two independent normally distributed populations given that the variances of the two populations are unknown but assumed equal, the classical two-sample t-test is recommended. If the underlying population distributions are normal with unequal and unknown variances, either Welch's t-statistic or Satterthwaite's Approximate F-test is suggested. However, Welch's procedure is non-robust under most non-normal distributions. There is a variable tolerance level around the strict assumptions of data independence, homogeneity of variances and normality of the distributions. Few textbooks offer alternatives when one or more of the underlying assumptions are not defensible.},
  number = {7},
  journal = {Journal of Applied Statistics},
  author = {Reed, James. F. and Stark, David B.},
  year = {2004},
  pages = {831 - 854}
}

@article{HodLeh63esti,
  title = {Estimates of Location Based on Rank Tests},
  volume = {34},
  number = {2},
  journal = {The Annals of Mathematical Statistics},
  author = {Hodges, J. L. and Lehmann, E. L.},
  year = {1963},
  pages = {598 - 611}
}

@article{FriDeh11robu,
  title = {Robust Nonparametric Tests for the Two Sample Location Problem},
  volume = {20},
  number = {4},
  journal = {Stat. Method Appl.},
  author = {Fried, R. and Dehling, H.},
  year = {2011},
  pages = {409 - 422}
}

@article{CreWhi86how,
  title = {How to Use the Two Sample T-Test},
  volume = {28},
  abstract = {This work discusses how two sample t-tests behave when applied to data that may violate the classical statistical assumptions of independence, heteroscedasticity and Gaussianity. The usual two sample t-statistic based on a pooled variance estimate and the Welch-Aspin statistic are treated in detail. Practical ``rules-of-thumb'' are given along with their applications to various examples so that readers will easily be able to use such tests on their own data sets.},
  number = {2},
  journal = {Biometrical Journal},
  author = {Cressie, Noel. A. and Whitford, H. J.},
  year = {1986},
  pages = {131 - 148}
}

@article{YueDix73appr,
  title = {The Approximate Behaviour and Performance of the Two-Sample Trimmed T},
  volume = {60},
  number = {2},
  journal = {Biometrika},
  author = {Yuen, Karen K. and Dixon, W. T.},
  year = {1973},
  pages = {369 - 374}
}

@article{Tik80robu,
  title = {Robustness of {{MML}} Estimators Based on Censored Samples and Robust Test Statistics},
  volume = {4},
  abstract = {We investigate the efficiences of Tiku's (1967) modified maximum likelihood estimators $\mu$c and $\sigma$c (based on symmetrically censored normal samples) for estimating the location and scale parameters $\mu$ and $\sigma$ of symmetric non-normal distributions. We show that $\mu$c and $\sigma$c are jointly more efficient than x\= and s for long-tailed distributions (kurtosis for the Logistic), and always more efficient than the trimmed mean $\mu$T and the matching sample estimate $\sigma$T of $\sigma$. We also show that $\mu$c and $\sigma$c are jointly at least as efficient as some of the more prominent ``robust'' estimators (Gross, 1976). We show that the statistic (r is the number of observations censored on each side of the sample and $\beta$ is a constant), is robust and powerful for testing an assumed value of $\mu$. We define a statistic Tc (based on $\mu$c and$\sigma$c) for testing that two symmetric distributions are identical and show that Tc is robust and generally more poweerful than the well-known nonparametric statistics (Wilcoxon, normal-score, Kolmogorov-Smirnov), against the important location-shift alternatives. We generalize the statistic Tc to test that k symmetric distibutions are identical. The asymptotic distributions of tc and Tc are normal, under some very general regularity conditions. For small samples, the upper (lower) percentage points of tc and Tc are shown to be closely approximated by Student's t-distributions. Besides, the statistics $\mu$c and $\sigma$c (and hence tc and Tc) are explicit and simple functions of sample observations and are easy to compute.},
  number = {2},
  journal = {Journal of Statistical Planning and Inference},
  author = {Tiku, M. L.},
  year = {1980},
  pages = {123 - 143}
}

@article{ReeSta96hing,
  title = {Hinge Estimators of Location: {{Robust}} to Asymmetry},
  volume = {49},
  abstract = {Robust estimators have been developed and tested for symmetric distributions via simulation studies. The primary objective of these robust estimators was to show that these estimators had a higher efficiency than the sample mean over these symmetric distributions. Little attention has been given to how these estimators perform on data that are from asymmetric distributions or from distributions that have inherent anomalies-so called `messy data'. This study is intended to supplement previous studies by examining the behavior of several robust estimators over asymmetric distributions. The objective is to demonstrate several adaptive `asymmetric' robust estimators which utilize sample selector statistics to identify the underlying distribution and to demonstrate the efficiency of these adaptive estimators. From a methodology point rather than a theoretical basis, reasonable alternatives should be available. In the asymmetric data distributions faced on a daily basis, estimators that adapt themselves to the data may be formulated and used. We recommend the use of the following algorithm in examining data sets: (a) compute the ancillary statisticsskewness and tail-length to classify the data distribution; (b) analyze each data set using at least one alternative estimator to the usual XM; (c) if the results are similar, report the XM analysis; (d) if the results are dissimilar, report the alternative analysis and the reasons for using the alternative analysis (i.e.,t-tests based on a T$\alpha$, HQ1, HQ2, or SK5).},
  number = {1},
  journal = {Computer Methods and Programs in Biomedicine},
  author = {Reed, James F. and Stark, David B.},
  year = {1996},
  pages = {11 - 17}
}

@article{HuaJinRob09robu,
  title = {Robust Permutation Tests for Two Samples},
  volume = {139},
  doi = {10.1016/j.jspi.2008.12.003},
  abstract = {We consider robust permutation tests for a location shift in the two sample case based on estimating equations, comparing the test statistics based on a score function and an M-estimate. First we obtain a form for both tests so that the exact tests may be carried out using the same algorithms as used for permutation tests based on the mean. Then we obtain the Bahadur slopes of the tests in these two statistics, giving numerical results for two cases equivalent to a test based on Huber scores and a particular case of this related to a median test. We show that they have different Bahadur slopes with neither exceeding the other over the whole range. Finally, we give some numerical results illustrating the robustness properties of the tests and confirming the theoretical results on Bahadur slopes.},
  number = {8},
  journal = {Journal of Statistical Planning and Inference},
  author = {Huang, Alan and Jin, Ruango and Robinson, John},
  year = {2009},
  pages = {2631 - 2642}
}

@article{Hoy65robu,
  title = {Robustness of the {{Hodges}}-{{Lehmann}} Estimates for Shift},
  volume = {36},
  number = {1},
  journal = {The Annals of Mathematical Statistics},
  author = {H\o{}yland, Arnljot},
  year = {1965},
  pages = {174 - 197}
}

@article{GhoMarBas17robu,
  title = {A New Class of Robust Two-Sample {{Wald}}-Type Tests},
  abstract = {Parametric hypothesis testing associated with two independent samples arises frequently in several
applications in biology, medical sciences, epidemiology, reliability and many more. In this paper, we
propose robust Wald-type tests for testing such two sample problems using the minimum density power
divergence estimators of the underlying parameters. In particular, we consider the simple two-sample
hypothesis concerning the full parametric homogeneity of the samples as well as the general two-sample
(composite) hypotheses involving nuisance parameters also. The asymptotic and theoretical robustness
properties of the proposedWald-type tests have been developed for both the simple and general composite
hypotheses. Some particular cases of testing against one-sided alternatives are discussed with specific
attention to testing the effectiveness of a treatment in clinical trials. Performances of the proposed tests
have also been illustrated numerically through appropriate real data examples.},
  journal = {arXiv:1702.04552 [stat.ME]},
  author = {Ghosh, Abhik and Martin, Nirian and Basu, Ayanendranath and Pardo, Leandro},
  year = {2017}
}

@article{Abo92robu,
  title = {Some Robust Two-Sample Test Statistics Based on {{M}}-Estimators of Location},
  volume = {21},
  abstract = {This paper describes a simulation experiment that
compares the performance, in terms of the size and a
function of the power, of four two-sample test
statistics based on M-estimators for location. M-estimates
are chosen to ensure similar levels of breakdown
point, gross error sensitivity and as far as possible,
similar rejection point. Two pairs of sample size and
six different distributions are involved. Matching
97.5\% critical values for the statistics are determined.},
  number = {1},
  journal = {Communications in Statistics - Simulation and Computation},
  author = {Aboukalam, M. A. F.},
  year = {1992},
  pages = {133 - 148}
}

@article{PhiSmy10perm,
  title = {Permutation p-values should never be zero: calculating exact p-values when permutations are randomly drawn},
  volume = {9},
  doi = {10.2202/1544-6115.1585},
  number = {1},
  journal = {Statistical Applications in Genetics and Molecular Biology},
  author = {Phipson, Belinda and Smyth, Gordon K.},
  year = {2010},
  pages = {Article 39}
}

@article{Hog74adap,
  title = {Adaptive Robust Procedures: {{A}} Partial Review and Some Suggestions for Future Applications and Theory},
  volume = {69},
  abstract = {After providing some background for the need to consider estimates other than those resulting from normal theory, there is a brief review of some nonadaptive robust estimators. We introduce adaptive estimators using those of Tukey and McLaughlin, Jaeckel, Johns, Birnbaum and Mik{\'e}, Takeuchi, H{\`a}jek, van Eeden, and Beran. Adaptive estimators based on preliminary testing and Stein-like procedures are then considered, and recommendations are made on how to select the amount of trimming. Various proposals for estimating regression coefficients are also considered. Adaptive distrubution-free tests look very promising for improving the power of nonparametric tests, and some of these techniques can be used effectively in data analysis. Asymmetric trimmed means, adapted to the particular sample, can easily be used with data and provide good descriptive statistics having an approximate error structure. Finally, it is conjectured that estimators based on ``cliff-hangers'' might be extremely effective if there are sharp changes in the height of the underlying density function.},
  number = {348},
  journal = {Journal of the American Statistical Association},
  author = {Hogg, Robert V.},
  year = {1974},
  pages = {909 - 923}
}

@book{Wil12intr,
  address = {Amsterdam},
  edition = {3},
  title = {Introduction to {{Robust Estimation}} and {{Hypothesis Testing}}},
  publisher = {{Elsevier}},
  author = {Wilcox, Rand R.},
  year = {2012}
}

@article{fried_rank_2007,
  title = {On {{Rank Tests}} for {{Shift Detection}} in {{Time Series}}},
  number = {52},
  journal = {Computational Statistics \& Data Analysis},
  author = {Fried, R. and Gather, U.},
  year = {2007},
  pages = {221 - 223}
}

@article{wilcox_modern_2003,
  title = {Modern {{Robust Data Analysis Methods}}: {{Measures}} of {{Central Tendency}}},
  volume = {8},
  number = {3},
  journal = {Psychological Methods},
  author = {Wilcox,, Rand R. and Keselmann, H. J.},
  year = {2003},
  pages = {254 - 274}
}

@article{YueDix73appr,
  title = {The {{Approximate Behaviour}} and {{Performance}} of the {{Two}}-{{Sample Trimmed T}}},
  volume = {60},
  number = {2},
  journal = {Biometrika},
  author = {Yuen, Karen K. and Dixon, W. T.},
  year = {1973},
  pages = {369-374}
}

@article{HodLeh63esti,
  title = {Estimates of {{Location Based}} on {{Rank Tests}}},
  volume = {34},
  number = {2},
  journal = {The Annals of Mathematical Statistics},
  author = {Hodges, J. L. and Lehmann, E. L.},
  year = {1963},
  pages = {598-611}
}

@article{FriDeh11robu,
  title = {Robust {{Nonparametric Tests}} for the {{Two Sample Location Problem}}},
  volume = {20},
  number = {4},
  journal = {Stat. Method Appl.},
  author = {Fried, R. and Dehling, H.},
  year = {2011},
  pages = {409-422}
}

@article{Abo92robu,
  title = {Some {{Robust Two}}-{{Sample Test Statistics Based}} on {{M}}-{{Estimators}} of {{Location}}},
  volume = {21},
  abstract = {This paper describes a simulation experiment thatcompares the performance, in terms of the size and afunction of the power, of four two-sample teststatistics based on M-estimators for location. M-estimatesare chosen to ensure similar levels of breakdownpoint, gross error sensitivity and as far as possible,similar rejection point. Two pairs of sample size andsix different distributions are involved. Matching97.5\% critical values for the statistics are determined.},
  number = {1},
  journal = {Communications in Statistics - Simulation and Computation},
  author = {Aboukalam, M. A. F.},
  year = {1992},
  pages = {133-148}
}

@article{GhoMarBas17robu,
  title = {A {{New Class}} of {{Robust Two}}-{{Sample Wald}}-{{Type Tests}}},
  abstract = {Parametric hypothesis testing associated with two independent samples arises frequently in severalapplications in biology, medical sciences, epidemiology, reliability and many more. In this paper, wepropose robust Wald-type tests for testing such two sample problems using the minimum density powerdivergence estimators of the underlying parameters. In particular, we consider the simple two-samplehypothesis concerning the full parametric homogeneity of the samples as well as the general two-sample(composite) hypotheses involving nuisance parameters also. The asymptotic and theoretical robustnessproperties of the proposedWald-type tests have been developed for both the simple and general compositehypotheses. Some particular cases of testing against one-sided alternatives are discussed with specificattention to testing the effectiveness of a treatment in clinical trials. Performances of the proposed testshave also been illustrated numerically through appropriate real data examples.},
  journal = {arXiv:1702.04552 [stat.ME]},
  author = {Ghosh, Abhik and Martin, Nirian and Basu, Ayanendranath and Pardo, Leandro},
  year = {2017}
}

@article{HuaJinRob09robu,
  title = {Robust {{Permutation Tests}} for {{Two Samples}}},
  volume = {139},
  doi = {10.1016/j.jspi.2008.12.003},
  abstract = {We consider robust permutation tests for a location shift in the two sample case based on estimating equations, comparing the test statistics based on a score function and an M-estimate. First we obtain a form for both tests so that the exact tests may be carried out using the same algorithms as used for permutation tests based on the mean. Then we obtain the Bahadur slopes of the tests in these two statistics, giving numerical results for two cases equivalent to a test based on Huber scores and a particular case of this related to a median test. We show that they have different Bahadur slopes with neither exceeding the other over the whole range. Finally, we give some numerical results illustrating the robustness properties of the tests and confirming the theoretical results on Bahadur slopes.},
  number = {8},
  journal = {Journal of Statistical Planning and Inference},
  author = {Huang, Alan and Jin, Ruango and Robinson, John},
  year = {2009},
  pages = {2631-2642}
}

@article{ReeSta04robu,
  title = {Robust {{Two}}-{{Sample Statistics}} for {{Testing Equality}} of {{Means}}: {{A Simulation Study}}},
  volume = {31},
  doi = {10.1080/0266476042000214529},
  abstract = {When testing the equality of the means from two independent normally distributed populations given that the variances of the two populations are unknown but assumed equal, the classical two-sample t-test is recommended. If the underlying population distributions are normal with unequal and unknown variances, either Welch's t-statistic or Satterthwaite's Approximate F-test is suggested. However, Welch's procedure is non-robust under most non-normal distributions. There is a variable tolerance level around the strict assumptions of data independence, homogeneity of variances and normality of the distributions. Few textbooks offer alternatives when one or more of the underlying assumptions are not defensible.},
  number = {7},
  journal = {Journal of Applied Statistics},
  author = {Reed, James. F. and Stark, David B.},
  year = {2004},
  pages = {831-854}
}

@article{Hoy65robu,
  title = {Robustness of the {{Hodges}}-{{Lehmann Estimates}} for {{Shift}}},
  volume = {36},
  number = {1},
  journal = {The Annals of Mathematical Statistics},
  author = {H\o{}yland, Arnljot},
  year = {1965},
  pages = {174-197}
}

@article{Yue74trim,
  title = {The {{Two}}-{{Sample Trimmed}} t for {{Unequal Population Variances}}},
  volume = {61},
  abstract = {The effect of nonnormality on the Welch approximate degrees of freedom t test is demonstrated.A two-sample trimmed t statistic for unequal population variances is proposed andits performance is also evaluated in comparison to the Welch t test under normality andunder long-tailed distributions. If the underlying distribution is long-tailed or contaminatedwith outliers, the trimmed t is strongly recommended.},
  number = {1},
  journal = {Biometrika},
  author = {Yuen, Karen K.},
  year = {1974},
  pages = {165-170}
}

@article{Tik80robu,
  title = {Robustness of {{MML Estimators Based}} on {{Censored Samples}} and {{Robust Test Statistics}}},
  volume = {4},
  abstract = {We investigate the efficiences of Tiku's (1967) modified maximum likelihood estimators $\mu$c and $\sigma$c (based on symmetrically censored normal samples) for estimating the location and scale parameters $\mu$ and $\sigma$ of symmetric non-normal distributions. We show that $\mu$c and $\sigma$c are jointly more efficient than x\= and s for long-tailed distributions (kurtosis for the Logistic), and always more efficient than the trimmed mean $\mu$T and the matching sample estimate $\sigma$T of $\sigma$. We also show that $\mu$c and $\sigma$c are jointly at least as efficient as some of the more prominent ``robust'' estimators (Gross, 1976). We show that the statistic (r is the number of observations censored on each side of the sample and $\beta$ is a constant), is robust and powerful for testing an assumed value of $\mu$. We define a statistic Tc (based on $\mu$c and$\sigma$c) for testing that two symmetric distributions are identical and show that Tc is robust and generally more poweerful than the well-known nonparametric statistics (Wilcoxon, normal-score, Kolmogorov-Smirnov), against the important location-shift alternatives. We generalize the statistic Tc to test that k symmetric distibutions are identical. The asymptotic distributions of tc and Tc are normal, under some very general regularity conditions. For small samples, the upper (lower) percentage points of tc and Tc are shown to be closely approximated by Student's t-distributions. Besides, the statistics $\mu$c and $\sigma$c (and hence tc and Tc) are explicit and simple functions of sample observations and are easy to compute.},
  number = {2},
  journal = {Journal of Statistical Planning and Inference},
  author = {Tiku, M. L.},
  year = {1980},
  pages = {123-143}
}

@article{ReeSta96hing,
  title = {Hinge {{Estimators}} of {{Location}}: {{Robust}} to {{Asymmetry}}},
  volume = {49},
  abstract = {Robust estimators have been developed and tested for symmetric distributions via simulation studies. The primary objective of these robust estimators was to show that these estimators had a higher efficiency than the sample mean over these symmetric distributions. Little attention has been given to how these estimators perform on data that are from asymmetric distributions or from distributions that have inherent anomalies-so called ‘messy data'. This study is intended to supplement previous studies by examining the behavior of several robust estimators over asymmetric distributions. The objective is to demonstrate several adaptive ‘asymmetric' robust estimators which utilize sample selector statistics to identify the underlying distribution and to demonstrate the efficiency of these adaptive estimators. From a methodology point rather than a theoretical basis, reasonable alternatives should be available. In the asymmetric data distributions faced on a daily basis, estimators that adapt themselves to the data may be formulated and used. We recommend the use of the following algorithm in examining data sets: (a) compute the ancillary statisticsskewness and tail-length to classify the data distribution; (b) analyze each data set using at least one alternative estimator to the usual XM; (c) if the results are similar, report the XM analysis; (d) if the results are dissimilar, report the alternative analysis and the reasons for using the alternative analysis (i.e.,t-tests based on a T$\alpha$, HQ1, HQ2, or SK5).},
  number = {1},
  journal = {Computer Methods and Programs in Biomedicine},
  author = {Reed, James F. and Stark, David B.},
  year = {1996},
  pages = {11-17}
}

@article{CreWhi86how,
  title = {How to {{Use}} the {{Two Sample T}}-{{Test}}},
  volume = {28},
  abstract = {This work discusses how two sample t-tests behave when applied to data that may violate the classical statistical assumptions of independence, heteroscedasticity and Gaussianity. The usual two sample t-statistic based on a pooled variance estimate and the Welch-Aspin statistic are treated in detail. Practical ``rules-of-thumb'' are given along with their applications to various examples so that readers will easily be able to use such tests on their own data sets.},
  number = {2},
  journal = {Biometrical Journal},
  author = {Cressie, Noel. A. and Whitford, H. J.},
  year = {1986},
  pages = {131-148}
}

@article{WeiHot02robu,
  title = {Robust {{Tests}} for the {{Two}}-{{Sample Location Problem}}},
  volume = {31},
  abstract = {The t-test is uniformly most powerful for comparing the location parameters of two normal distributed populations. For non-normal data, robust tests can be more powerful than the t-test. We introduce a new parametric test statistic combining the p-values of the t-test and robust tests. In the normal distribution situation, this new test has a very small power loss compared to the t-test, but in the non-normal situation higher power than the t-test. The Pitman efficiency of 3$\pi$-1 = 0.955 gives an upper bound on the efficiency of nonparametric tests in the normal situation. Our new test (which is parametric) exceeds the Pitman bound when the sample sizes are small.},
  number = {2},
  journal = {Communications in Statistics - Simulation and Computation},
  author = {Weichert, Michael and Hothorn, Ludwig A.},
  year = {2002},
  pages = {175-187}
}

@article{Lam85robu,
  title = {Robust {{Two}}-{{Sample Permutation Tests}}},
  volume = {13},
  abstract = {A new two-sample randomization test is proposed for testing that the joint distribution of two samples is invariant under permutations. The p-value of the test has a finite sample minimaxity property over neighborhoods of completely specified alternative distributions. Asymptotically, the test has minimax Bahadur slope against the neighborhoods, which remain fixed as the sample sizes increase. The proposed test also offers the best compromise between robustness against departures from a model alternative and optimality at the model alternative in the sense that no other test with the same gross-error-sensitivity has larger slope at the model. Some modifications of the test are proposed for testing the nonparametric null hypothesis against neighborhoods of models that have a shared nuisance location-scale parameter. These nuisance-parameter-free versions of the test are justified for large samples from exponential families, and an example of their use is given.},
  number = {2},
  journal = {The Annals of Statistics},
  author = {Lambert, Diane},
  year = {1985},
  pages = {606-625}
}

@article{Rom89boot,
  title = {Bootstrap and {{Randomization Tests}} of {{Some Nonparametric Hypothesis}}},
  volume = {17},
  abstract = {In this paper, the asymptotic behavior of some nonparametric tests is studied in situations where both bootstrap tests and randomization tests are applicable. Under fairly general conditions, the tests are asymptotically equivalent in the sense that the resulting critical values and power functions are appropriately close. This implies, among other things, that the difference in the critical functions of the tests, evaluated at the observed data, tends to 0 in probability. Randomization tests may be preferable since an exact desired level of the test may be obtained for finite samples. Examples considered are: testing independence, testing for spherical symmetry, testing for exchangeability, testing for homogeneity, and testing for a change point.},
  number = {1},
  journal = {The Annals of Statistics},
  author = {Romano, Joseph P.},
  year = {1989},
  pages = {141-159}
}

@article{Rom90beha,
  title = {On the {{Behaviour}} of {{Randomization Tests}} without a {{Group Invariance Assumption}}},
  volume = {85},
  abstract = {Fisher's randomization construction of hypothesis tests is a powerful tool to yield tests that are nonparametric in nature in that their level is exactly equal to the nominal level in finite samples over a wide range of distributional assumptions. For example, the usual permutation t test to test equality of means is valid without a normality assumption of the underlying populations. On the other hand, Fisher's randomization construction is not applicable in this example unless the underlying populations differ only in location. In general, the basis for the randomization construction is invariance of the probability distribution of the data under a transformation group. It is the goal of this article to understand the robustness properties of randomization tests by studying their asymptotic validity in situations where the basis for their construction breaks down. Here, asymptotic validity refers to whether the probability of a Type I error tends asymptotically to the nominal level. In particular, it is shown that the randomization construction is generally asymptotically valid for certain one-sample problems, such as for testing a mean or a median, even when the underlying population is not symmetric. In contrast, the randomization construction for two- sample problems may yield invalid tests, though it depends on the precise nature of the problem. For example, the two-sample permutation test based on sample means is generally asymptotically valid only if the samples are of the same size. When comparing medians, however, the two-sample permutation test is generally invalid even if the sample sizes are equal.},
  number = {411},
  journal = {Journal of the American Statistical Association},
  author = {Romano, Joseph P.},
  year = {1990},
  pages = {686-692}
}

@article{Neu15comb,
  title = {Combining the T-Test and {{Wilcoxon}}'s Rank-Sum Test},
  volume = {42},
  abstract = {In the two-sample location-shift problem, Student's t test or Wilcoxon's rank-sum test are commonly applied. The latter test can be more powerful for non-normal data. Here, we propose to combine the two tests within a maximum test. We show that the constructed maximum test controls the type I error rate and has good power characteristics for a variety of distributions; its power is close to that of the more powerful of the two tests. Thus, irrespective of the distribution, the maximum test stabilizes the power. To carry out the maximum test is a more powerful strategy than selecting one of the single tests. The proposed test is applied to data of a clinical trial.},
  number = {12},
  journal = {Journal of Applied Statistics},
  author = {Neuh{\"a}user, Markus},
  year = {2015},
  pages = {2769 - 2775}
}

@article{Mar02boot,
  title = {Bootstrap Tests for Robust Means of Asymmetric Distributions with Unequal Shapes},
  volume = {39},
  abstract = {Bootstrap procedures for testing equality of robust means in the one-, two-, and multi-sample problems for asymmetrically distributed data with unequal shapes are described. The emphasis is on parametric procedures, but some results are provided for nonparametric procedures as well. In the parametric framework, it is assumed that a model with two parameters, shape and scale, can be used to approximatively describe the populations. Examples are contaminated Lognormal, Weibull, Gamma, and Pareto distributions. Robust estimators of the parameters are supposed to be available; the robust mean is then defined as the asymptotic value of the robust estimate of the model mean. In the nonparametric framework, the robust mean is the asymptotic value of some estimate that does not depend on a parametric model, e.g., a trimmed mean. A studentized test statistic is explored with the help of examples on simulated and real data. In order to estimate the null model, criteria for robust constrained model fitting, the constraint being the null hypothesis, are introduced and discussed. In the nonparametric case, a robust version of exponential tilting is provided. Parametric, semiparametric, and nonparametric bootstrap schemes for the computation of finite sample distributions are considered. The examples illustrate procedures that can be useful in practice.},
  number = {4},
  journal = {Computational Statistics \& Data Analysis},
  author = {Marazzi, Alfio},
  year = {2002},
  pages = {503 - 528}
}

@article{Tik82robu,
  title = {Robust Statistics for Testing Equality of Means or Variances},
  volume = {11},
  number = {22},
  journal = {Communications in Statistics - Theory and Methods},
  author = {Tiku, M. L.},
  year = {1982},
  pages = {2543 - 2558}
}

@article{KesOthWil04impr,
  title = {The New and Improved Two-Sample t-Test},
  volume = {15},
  abstract = {This article considers the problem of comparing two independent groups in terms of some measure of location. It is well known that with Student's two-independent-sample t test, the actual level of significance can be well above or below the nominal level, confidence intervals can have inaccurate probability coverage, and power can be low relative to other methods. A solution to deal with heterogeneity is Welch's (1938) test. Welch's test deals with heteroscedasticity but can have poor power under arbitrarily small departures from normality. Yuen (1974) generalized Welch's test to trimmed means; her method provides improved control over the probability of a Type I error, but problems remain. Transformations for skewness improve matters, but the probability of a Type I error remains unsatisfactory in some situations. We find that a transformation for skewness combined with a bootstrap method improves Type I error control and probability coverage even if sample sizes are small.},
  number = {1},
  journal = {Psychological Science},
  author = {Keselman, H. J. and Othman, Abdul R. and Wilcox, Rand. R. and Fradette, Katherine},
  year = {2004},
  pages = {47 - 51}
}

@article{XuCuiGup09impr,
  title = {Improved Statistics for Contrasting Means of Two Samples under Non-Normality},
  volume = {62},
  abstract = {This paper presents the asymptotic expansions of the distributions of the two-sample t-statistic and the Welch statistic, for testing the equality of the means of two independent populations under non-normality. Unlike other approaches, we obtain the null distributions in terms of the distribution and density functions of the standard normal variable up to n\textasciitilde, where n-1 is the pooled sample size. Based on these expansions, monotone transformations are employed to remove the higher-order cumulant effect. We show that the new statistics can improve the precision of statistical inference to the level of o (n-1) Numerical studies are carried out to demonstrate the performance of the improved statistics. Some general rules for practitioners are also recommended.},
  number = {1},
  journal = {British Journal of Mathematical and Statistical Psychology},
  author = {Xu, Jin and Cui, Xinping and Gupta, Arjun K.},
  year = {2009},
  pages = {21 - 40}
}

@article{Wil96note,
  title = {A Note on Testing Hypothesis about Trimmed Means},
  volume = {38},
  shorttitle = {Biom. {{J}}.},
  abstract = {A well known result is that skewness can cause problems when testing hypotheses about measures of location, particularly when a one-sided test is of interest. Wilcox (1994) reports both theoretical and simulation results showing that when testing hypotheses about trimmed means, control over Type I error probabilities can be substantially better than methods for means. However, at least in some situations, control over the probability of a Type I error might still be judged to be inadequate. One way of addressing this concern is to combine trimmed means with the bootstrap method advocated by Westfall and Yuong (1993). This note reports simulation results indicating that there are situations where substantial improvements over Type I error probabilities are indeed obtained.},
  number = {2},
  journal = {Biometrical Journal},
  author = {Wilcox, Rand R.},
  year = {1996},
  pages = {173 - 180}
}

@article{Rom89boot,
  title = {Bootstrap and Randomization Tests of Some Nonparametric Hypothesis},
  volume = {17},
  abstract = {In this paper, the asymptotic behavior of some nonparametric tests is studied in situations where both bootstrap tests and randomization tests are applicable. Under fairly general conditions, the tests are asymptotically equivalent in the sense that the resulting critical values and power functions are appropriately close. This implies, among other things, that the difference in the critical functions of the tests, evaluated at the observed data, tends to 0 in probability. Randomization tests may be preferable since an exact desired level of the test may be obtained for finite samples. Examples considered are: testing independence, testing for spherical symmetry, testing for exchangeability, testing for homogeneity, and testing for a change point.},
  number = {1},
  journal = {The Annals of Statistics},
  author = {Romano, Joseph P.},
  year = {1989},
  pages = {141 - 159}
}

@article{Oez13comp,
  title = {Comparing Two Independent Groups: {{A}} Test Based on a One-Step {{M}}-Estimator and Bootstrap- T},
  volume = {66},
  abstract = {A new test is proposed for the problem of comparing two independent groups in terms of some measure of location. The proposed test () uses a one-step M-estimator and a bootstrap- t method with the procedure proposed by {\"O}zdemir and Kurt (2006). Eight methods were compared in terms of actual Type I error and power when the underlying distributions differ in skewness and kurtosis under heterogeneity of variances. For the 21 theoretical distributions, the Yuen test with the bootstrap- t method was the most favourable, followed by test. For the five real data sets, the proposed test and percentile bootstrap method with the one-step M-estimator performed best.},
  number = {2},
  journal = {British Journal of Mathematical and Statistical Psychology},
  author = {{\"O}zdemir, Firat A:},
  year = {2013},
  pages = {322 - 337}
}

@article{Wil94some,
  title = {Some Results on the {{Tukey}}-{{McLaughlin}} and {{Yuen}} Methods for Trimmed Means When Distributions Are Skewed},
  volume = {36},
  abstract = {In applied work, distributions are often highly skewed with heavy tails, and this can have disastrous consequences in terms of power when comparing groups based on means. One solution to this problem in the one-sample case is to use the TUKEY and MCLAUGHLIN (1963) method for trimmed means, while in the two-group case YUEN's (1974) method can be used. Published simulations indicate that they yield accurate confidence intervals when distributions are symmetric. Using a Cornish-Fisher expansion, this paper extends these results by describing general circumstances under which methods based on trimmed means can be expected to give more accurate confidence intervals than those based on means. The results cover both symmetric and asymmetric distributions. Simulations are also used to illustrate the accuracy of confidence intervals using trimmed means versus means.},
  number = {3},
  journal = {Biometrical Journal},
  author = {Wilcox, Rand R.},
  year = {1994},
  pages = {259 - 273},
  file = {C:\\Users\\Barbara\\Zotero\\storage\\LITTMTBY\\Wilcox - 1994 - Some results on the Tukey-McLaughlin and Yuen meth.pdf}
}

@article{Wil92comp,
  title = {Comparing One-Step {{M}}-Estimators of Location Corresponding to Two Independent Groups},
  volume = {57},
  abstract = {Experience with real data indicates that psychometric measures often have heavy-tailed distributions. This is known to be a serious problem when comparing the means of two independent groups because heavy-tailed distributions can have a serious effect on power. Another problem that is common in some areas is outliers. This paper suggests an approach to these problems based on the one-step M-estimator of location. Simulations indicate that the new procedure provides very good control over the probability of a Type I error even when distributions are skewed, have different shapes, and the variances are unequal. Moreover, the new procedure has considerably more power than Welch's method when distributions have heavy tails, and it compares well to Yuen's method for comparing trimmed means. Wilcox's median procedure has about the same power as the proposed procedure, but Wilcox's method is based on a statistic that has a finite sample breakdown point of only l/n, where n is the sample size. Comments on other methods for comparing groups are also included.},
  number = {1},
  journal = {Psychometrika},
  author = {Wilcox, Rand R.},
  year = {1992},
  pages = {141 - 154}
}

@article{Wil90comp,
  title = {Comparing the Means of Two Independent Groups},
  volume = {82},
  abstract = {Recently, CRESSIE and WHITFORD (1986) showed that Welch's test of H0: mu-1 = mu-2 can be biased, under nonnormality, where mu-1 and mu-2 are the means of two independent treatment groups. They suggested, therefore, that a two-sample analog of Johnson's test be used instead. One goal in this paper is to examine the extent to which a two-sample analog of Johnson's test improves upon Welch's technique in terms of Type I errors and power when sample sizes are small or moderately large. Several alternative procedures are also considered including an additional modification of Johnson's procedure, a procedure suggested by DUNNETT (1982) that uses Tiku's modified maximum likelihood estimate with 10\% trimming, two versions of Efron's bootstrap, and a test recently proposed by WILCOX (1989). The paper also describes situations where Welch's procedure is not robust in terms of Type I errors. This is important because based on results currently available, Welch's procedure is thought to be nonrobust in terms of power, but robust in terms of Type I errors.},
  number = {7},
  journal = {Biometrical Journal},
  author = {Wilcox, Rand R.},
  year = {1990},
  pages = {771 - 780}
}

@article{WanTonZha17new,
  title = {New Two-Sample Tests for Skewed Populations and Their Connection to Theoretical Power of {{Bootstrap}}-t Test},
  volume = {26},
  abstract = {Various tests are available to compare the means of two populations. Tests for skewed data, however, are not well studied even though they are often needed in pharmaceutical study and agricultural economics. In particular, there is no available result to give power and sample size calculation for a two-sample Bootstrap-t test in skewed populations. In this paper, we propose easy-to-compute new tests and study their theoretical properties. The proposed work starts with derivation of a second-order Edgeworth expansion for the pooled two-sample t-statistic. Then new test rejection regions are formed based on Cornish\textendash{}Fisher expansion of quantiles. The new tests account for first-order and second-order population skewnesses that were ignored in two-sample t test. We report the theoretical type I error accuracy and power of the newly proposed tests and the large sample t test. We also provide the detailed conditions under which the proposed tests give better power than the two-sample large sample test. Our new tests, TCF1 and TCF, are asymptotically equivalent to Bootstrap-t test up to O(N-1) and O(N-3/2), respectively. Compared with commonly used two-sample parametric and nonparametric tests, the new tests are computationally efficient, give better power for skewed data with moderate sample size, and provide sample size calculation to achieve desired power at a given significance level. Empirical studies confirmed our theoretical results.},
  number = {3},
  journal = {TEST},
  author = {Wang, Haiyan and Tong, Bo and Zhang, Huaiyu and Li, Xukun},
  year = {2017},
  pages = {661 - 683}
}

@article{Rom90beha,
  title = {On the Behaviour of Randomization Tests without a Group Invariance Assumption},
  volume = {85},
  abstract = {Fisher's randomization construction of hypothesis tests is a powerful tool to yield tests that are nonparametric in nature in that their level is exactly equal to the nominal level in finite samples over a wide range of distributional assumptions. For example, the usual permutation t test to test equality of means is valid without a normality assumption of the underlying populations. On the other hand, Fisher's randomization construction is not applicable in this example unless the underlying populations differ only in location. In general, the basis for the randomization construction is invariance of the probability distribution of the data under a transformation group. It is the goal of this article to understand the robustness properties of randomization tests by studying their asymptotic validity in situations where the basis for their construction breaks down. Here, asymptotic validity refers to whether the probability of a Type I error tends asymptotically to the nominal level. In particular, it is shown that the randomization construction is generally asymptotically valid for certain one-sample problems, such as for testing a mean or a median, even when the underlying population is not symmetric. In contrast, the randomization construction for two- sample problems may yield invalid tests, though it depends on the precise nature of the problem. For example, the two-sample permutation test based on sample means is generally asymptotically valid only if the samples are of the same size. When comparing medians, however, the two-sample permutation test is generally invalid even if the sample sizes are equal.},
  number = {411},
  journal = {Journal of the American Statistical Association},
  author = {Romano, Joseph P.},
  year = {1990},
  pages = {686 - 692}
}

@article{Ree05cont,
  title = {Contributions to Two-Sample Statistics},
  volume = {32},
  abstract = {When testing the equality of the means from two independent normally distributed populations given that the variances of the two populations are unknown but assumed equal, the classical Student's two-sample t-test is recommended. If the underlying population distributions are normal with unequal and unknown variances, either Welch's t-statistic or Satterthwaite's approximate F test is suggested. However, Welch's procedure is non-robust under most non-normal distributions. There is a variable tolerance level around the strict assumptions of data independence, homogeneity of variances, and identical and normal distributions. Few textbooks offer alternatives when one or more of the underlying assumptions are not defensible. While there are more than a few non-parametric (rank) procedures that provide alternatives to Student's t-test, we restrict this review to the promising alternatives to Student's two-sample t-test in non-normal models.},
  number = {1},
  journal = {Journal of Applied Statistics},
  author = {Reed, James. F.},
  year = {2005},
  pages = {37 - 44}
}

@misc{MaiSchWil17wrs2,
  title = {{{WRS2}}: {{Wilcox}} Robust Estimation and Testing},
  author = {Mair, Patrick and Schoenbrodt, Felix and Wilcox, Rand R.},
  year = {2017}
}

@article{Lam85robu,
  title = {Robust Two-Sample Permutation Tests},
  volume = {13},
  abstract = {A new two-sample randomization test is proposed for testing that the joint distribution of two samples is invariant under permutations. The p-value of the test has a finite sample minimaxity property over neighborhoods of completely specified alternative distributions. Asymptotically, the test has minimax Bahadur slope against the neighborhoods, which remain fixed as the sample sizes increase. The proposed test also offers the best compromise between robustness against departures from a model alternative and optimality at the model alternative in the sense that no other test with the same gross-error-sensitivity has larger slope at the model. Some modifications of the test are proposed for testing the nonparametric null hypothesis against neighborhoods of models that have a shared nuisance location-scale parameter. These nuisance-parameter-free versions of the test are justified for large samples from exponential families, and an example of their use is given.},
  number = {2},
  journal = {The Annals of Statistics},
  author = {Lambert, Diane},
  year = {1985},
  pages = {606 - 625}
}

@article{KesWilLix07adap,
  title = {Adaptive Robust Estimation and Testing},
  volume = {60},
  abstract = {We examined nine adaptive methods of trimming, that is, methods that empirically determine when data should be trimmed and the amount to be trimmed from the tails of the empirical distribution. Over the 240 empirical values collected for each method investigated, in which we varied the total percentage of data trimmed, sample size, degree of variance heterogeneity, pairing of variances and group sizes, and population shape, one method resulted in exceptionally good control of Type I errors. However, under less extreme cases of non-normality and variance heterogeneity a number of methods exhibited reasonably good Type I error control. With regard to the power to detect non-null treatment effects, we found that the choice among the methods depended on the degree of non-normality and variance heterogeneity. Recommendations are offered.},
  number = {2},
  journal = {British Journal of Mathematical and Statistical Psychology},
  author = {Keselman, H. J. and Wilcox, Rand. R. and Lix, Lisa M. and Algina, James and Fradette, Katherine},
  year = {2007},
  pages = {267 - 293}
}

@article{Fri07robu,
  title = {On the Robust Detection of Edges in Time Series Filtering},
  volume = {52},
  abstract = {Abrupt shifts in the level of a time series represent important information and should be preserved in statistical signal extraction. Various rules for detecting level shifts that are resistant to outliers and which work with only a short time delay are investigated. The properties of robustified versions of the t-test for two independent samples and its non-parametric alternatives are elaborated under different types of noise. Trimmed t-tests, median comparisons, robustified rank and ANOVA tests based on robust scale estimators are compared.},
  number = {2},
  journal = {Computational Statistics \& Data Analysis},
  author = {Fried, Roland},
  year = {2007},
  pages = {1063 - 1074}
}

@book{EfrTib98intr,
  address = {Boca Raton},
  title = {An Introduction to the Bootstrap},
  publisher = {{Chapman \& Hall CRC}},
  author = {Efron, Bradley and Tibshirani, Robert},
  year = {1998}
}

@article{Wel47gene,
  title = {The Generalization of {{Students}} Problem When Several Different Population Variances Are Involved},
  volume = {34},
  shorttitle = {Biometrika},
  number = {1 - 2},
  journal = {Biometrika},
  author = {Welch, B. L.},
  year = {1947},
  pages = {28 - 35}
}

@book{Wil03appl,
  address = {Amsterdam},
  title = {Applying Contemporary Statistical Techniques},
  publisher = {{Academic Press}},
  author = {Wilcox, Rand R.},
  year = {2003}
}

@book{LehRom05test,
  address = {New York},
  edition = {3},
  title = {Testing {{Statistical Hypothesis}}},
  abstract = {The third edition of Testing Statistical Hypotheses updates and expands upon the classic graduate text, emphasizing optimality theory for hypothesis testing and confidence sets. The principal additions include a rigorous treatment of large sample optimality, together with the requisite tools. In addition, an introduction to the theory of resampling methods such as the bootstrap is developed. The sections on multiple testing and goodness of fit testing are expanded. The text is suitable for Ph.D. students in statistics and includes over 300 new problems out of a total of more than 760.},
  publisher = {{Springer}},
  author = {Lehmann, Erich L. and Romano, Joseph P.},
  year = {2005}
}

@article{FriGat07rank,
  title = {On Rank Tests for Shift Detection in Time Series},
  volume = {52},
  journal = {Computational Statistics \& Data Analysis},
  author = {Fried, Roland and Gather, Ursula},
  year = {2007},
  pages = {221 - 233}
}

@book{StaShe90robu,
  address = {New York},
  title = {Robust {{Estimation}} and {{Testing}}},
  publisher = {{Wiley}},
  author = {Staudte, Robert G. and Sheather, Simon J.},
  year = {1990}
}

@article{YueLeeTaj85some,
  title = {Some Robust Test Statistics for the Two-Sample Location Problem},
  volume = {34},
  number = {2},
  journal = {The Statististician},
  author = {Yuen Fung, Karen and Lee, Hyunshik and Tajuddin, I.},
  year = {1985},
  pages = {175 - 182}
}

@book{Hub81robu,
  address = {New York},
  title = {Robust {{Statistics}}},
  publisher = {{Wiley}},
  author = {Huber, Peter J.},
  year = {1981}
}

@book{Leh83theo,
  address = {New York},
  title = {Theory of Point Estimation},
  publisher = {{Wiley}},
  author = {Lehmann, Erich L.},
  year = {1983}
}

@book{MarMarYoh06robu,
  title = {Robust Statistics: {{Theory}} and Methods},
  publisher = {{Wiley, Chichester}},
  author = {Maronna, Ricardo A. and Martin, Douglas R. and Yohai, V{\'\i}ctor J.},
  year = {2006}
}

@article{Fri12onli,
  title = {On the online estimation of piecewise constant volatilities},
  author = {Fried, Roland},
  year = {2012},
  volume = {56},
  pages = {3080--3090},
  journal = {Computational Statistics \& Data Analysis},
  doi = {10.1016/j.csda.2011.02.012},
  number = {11}
}


